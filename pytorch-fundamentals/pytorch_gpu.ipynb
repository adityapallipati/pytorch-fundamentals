{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdfXoLR1_tXn",
        "outputId": "05f14dcd-b21f-4eee-e6be-e91517cfb4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Nov 17 21:22:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_20lgCE-ASAu",
        "outputId": "df13f49f-7134-40bd-bc6a-7bf8d9750e17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IPA8P3m_AWLO",
        "outputId": "fb439c3f-c78c-49fa-9725-4a0823d16b48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUzguetKAqbU",
        "outputId": "23cd54b6-f7da-4494-dae6-0ba7bafeb3e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDGiBaYgB8RM"
      },
      "source": [
        "## Switching From Colab to Local M1 MBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH420eV-AsvU",
        "outputId": "e63aa590-1393-4181-9270-0f0499319d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for Apple Silicon GPU\n",
        "import torch\n",
        "torch.backends.mps.is_available() # Note this will print false if you're not running on a Mac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LaaHpx1B8RN",
        "outputId": "b1f22a16-35e1-45b9-8ad1-93c80607f0cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mps'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETuv1YDnB8RN"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
        "else:\n",
        "    device = \"cpu\" # Default to CPU if no GPU is available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HdSc4iYB8RN"
      },
      "source": [
        "## Switch back to Colab\n",
        "\n",
        "Putting a tensor on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5P3wSXAB8RN",
        "outputId": "97aa880d-4141-48b3-b7ff-531a3fc0e33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Uct9VEIhCAI8",
        "outputId": "8874aee1-d591-4eec-9f61-107c67e24431"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-53175578f49e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52xxW_bbCVg5",
        "outputId": "e1aa588a-5718-42c0-95b4-62be5578d6b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7md7EeFtCX81",
        "outputId": "0660bb49-d3ab-4b7a-a6d8-e415cf75a641"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4_NLiV0MRoK"
      },
      "source": [
        "**Exercises**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gxR831DiCZxA",
        "outputId": "fcef12b4-f1b4-4c9f-b683-375baee352cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Create a random tensor with shape (7,7)\n",
        "\n",
        "import torch\n",
        "RANDOM_TENSOR = torch.rand(7, 7)\n",
        "\n",
        "RANDOM_TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMTiMHxjMRoK",
        "outputId": "860013cd-462a-418b-af85-a514ce5e1744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.9646],\n",
              "        [1.3812],\n",
              "        [0.9231],\n",
              "        [1.4890],\n",
              "        [1.7523],\n",
              "        [1.7268],\n",
              "        [1.6211]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform a matrix multiplication on the tensor with another random tensor with shape (1, 7)\n",
        "\n",
        "RANDOM_TENSOR_2 = torch.rand(1,7)\n",
        "\n",
        "mat_mul = torch.matmul(RANDOM_TENSOR, RANDOM_TENSOR_2.T)\n",
        "mat_mul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl5U1aL3MRoK",
        "outputId": "aa1d47a5-cab2-4557-9755-298e46e89b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor 1 Shape: torch.Size([7, 7])\n",
            "Tensor 2 Shape: torch.Size([1, 7])\n",
            "tensor([[1.8542],\n",
            "        [1.9611],\n",
            "        [2.2884],\n",
            "        [3.0481],\n",
            "        [1.7067],\n",
            "        [2.5290],\n",
            "        [1.7989]])\n"
          ]
        }
      ],
      "source": [
        "# set the random seed to 0 and attempt above again\n",
        "\n",
        "RANDOM_SEED = 0\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "a = torch.rand(7, 7)\n",
        "print(f\"Tensor 1 Shape: {a.shape}\")\n",
        "\n",
        "b = torch.rand(1, 7)\n",
        "print(f\"Tensor 2 Shape: {b.shape}\")\n",
        "\n",
        "matmul = torch.matmul(a, b.T)\n",
        "print(matmul)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JA8JEokLMRoL",
        "outputId": "edefcf83-a37a-47ac-f9b7-3262683b61fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78a1d00f0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "RANDOM_SEED = 1234\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "\n",
        "print(device)\n",
        "a = torch.rand(2, 3, device=device)\n",
        "b = torch.rand(2, 3, device=device)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "BLFViHFKMgsG",
        "outputId": "00d40879-301f-45b4-fa6f-523d43f8e51e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([[0.1272, 0.8167, 0.5440],\n",
            "        [0.6601, 0.2721, 0.9737]], device='cuda:0')\n",
            "tensor([[0.6208, 0.0276, 0.3255],\n",
            "        [0.1114, 0.6812, 0.3608]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = torch.matmul(a,b.T)\n",
        "res"
      ],
      "metadata": {
        "id": "iHPK5i9aM8k3",
        "outputId": "cc597a4a-2118-4f17-c62b-ad1f9ca9f103",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2786, 0.7668],\n",
              "        [0.7343, 0.6102]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(res)"
      ],
      "metadata": {
        "id": "yjraRMvIN5cT",
        "outputId": "eebea2e8-107b-4ecd-d119-6f0178095d01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7668, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(res)"
      ],
      "metadata": {
        "id": "hyEphKKpOPas",
        "outputId": "99fcf10e-afe2-4158-f44f-0c07eff7c3d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2786, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(res[-1])"
      ],
      "metadata": {
        "id": "-XitUAWWOdh6",
        "outputId": "baf9600b-4d35-4349-b45a-9ae964b77112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6102, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(res[-1])"
      ],
      "metadata": {
        "id": "UwmgtCKoRrYq",
        "outputId": "97073857-6aa0-4d21-fcdf-20442f6a66b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7343, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the random seed\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Create a random tensor with shape (1, 1, 1, 10)\n",
        "tensor_1 = torch.rand(1, 1, 1, 10)\n",
        "print(f\"Tensor 1: {tensor_1}\")\n",
        "print(f\"Tensor 1 Shape: {tensor_1.shape}\")\n",
        "\n",
        "# Remove all singleton dimensions\n",
        "tensor_2 = tensor_1.squeeze()\n",
        "print(f\"Tensor 2: {tensor_2}\")\n",
        "print(f\"Tensor 2 Shape: {tensor_2.shape}\")"
      ],
      "metadata": {
        "id": "YX5y5LQNR1R8",
        "outputId": "c1b5ce88-4126-478d-c062-1bf9ce259ecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1: tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]])\n",
            "Tensor 1 Shape: torch.Size([1, 1, 1, 10])\n",
            "Tensor 2: tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513])\n",
            "Tensor 2 Shape: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhQewOloSR41"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch-learn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}